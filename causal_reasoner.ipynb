{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "signal-tucson",
   "metadata": {},
   "source": [
    "# ROCK: Reasoning About Commonsense Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-denmark",
   "metadata": {},
   "source": [
    "Use this notebook for performing CCR using ROCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aboriginal-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys, os, json, time, datetime, logging, warnings, multiprocessing, itertools\n",
    "import tqdm, json, sqlite3, ast\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk, spacy\n",
    "import transformers, allennlp\n",
    "from transformers import (AutoTokenizer, AutoModelForMaskedLM,\n",
    "                          RobertaModel,RobertaForMaskedLM, \n",
    "                          RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer)\n",
    "import allennlp_models\n",
    "import allennlp_models.pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behind-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import src.pipeline\n",
    "import src.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norwegian-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "TORCH_DEV = torch.device(f'cuda:0') if torch.cuda.is_available() \\\n",
    "                                    else torch.device(\"cpu\")\n",
    "\n",
    "logging.getLogger('allennlp.common.params').disabled = True \n",
    "logging.getLogger('allennlp.nn.initializers').disabled = True \n",
    "logging.getLogger('allennlp.modules.token_embedders.embedding').setLevel(logging.INFO) \n",
    "logging.getLogger('urllib3.connectionpool').disabled = True \n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.disable(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hungry-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def console_log(msg, end='\\n'):\n",
    "    os.write(1, ('[LOG/{}]'.format(multiprocessing.current_process().name)+msg+end).encode('utf-8'))\n",
    "\n",
    "\n",
    "def col_print(*args, cw=12, sep='|'):\n",
    "    print(f\" {sep} \".join(('{'+f\":<{cw}\"+'}').format(s) for s in args))\n",
    "    \n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "def set_ts_seed():\n",
    "    set_seed(int(str(datetime.datetime.now().timestamp()).replace('.', '')) % (2 ** 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb187a",
   "metadata": {},
   "source": [
    "[Process path `from pathlib import Path`](https://www.freecodecamp.org/news/how-to-use-pathlib-module-in-python/#:~:text=Concrete%20Paths%20in%20Python,being%20in%20that%20operating%20system.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "racial-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"./exp_data\")\n",
    "MODEL_PATH = Path(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thick-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed(hsh('random_string') % (2 ** 31))\n",
    "set_ts_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-tribune",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minimal-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_dev = pd.read_json(DATA_PATH / \"copa_dev.json\", lines=True, orient='records').set_index('idx')\n",
    "copa_test = pd.read_csv(DATA_PATH / \"copa_test.json\")\n",
    "glt_d1 = pd.read_csv(DATA_PATH / \"glucose_d1_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c445f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The man turned on the faucet.</td>\n",
       "      <td>The toilet filled with water.</td>\n",
       "      <td>Water flowed from the spout.</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The girl found a bug in her cereal.</td>\n",
       "      <td>She poured milk in the bowl.</td>\n",
       "      <td>She lost her appetite.</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The woman retired.</td>\n",
       "      <td>She received her pension.</td>\n",
       "      <td>She paid off her mortgage.</td>\n",
       "      <td>effect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanted to conserve energy.</td>\n",
       "      <td>I swept the floor in the unoccupied room.</td>\n",
       "      <td>I shut off the light in the unoccupied room.</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The hamburger meat browned.</td>\n",
       "      <td>The cook froze it.</td>\n",
       "      <td>The cook grilled it.</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 premise  \\\n",
       "idx                                        \n",
       "0          The man turned on the faucet.   \n",
       "1    The girl found a bug in her cereal.   \n",
       "2                     The woman retired.   \n",
       "3           I wanted to conserve energy.   \n",
       "4            The hamburger meat browned.   \n",
       "\n",
       "                                       choice1  \\\n",
       "idx                                              \n",
       "0                The toilet filled with water.   \n",
       "1                 She poured milk in the bowl.   \n",
       "2                    She received her pension.   \n",
       "3    I swept the floor in the unoccupied room.   \n",
       "4                           The cook froze it.   \n",
       "\n",
       "                                          choice2 question  label  \n",
       "idx                                                                \n",
       "0                    Water flowed from the spout.   effect      1  \n",
       "1                          She lost her appetite.   effect      1  \n",
       "2                      She paid off her mortgage.   effect      0  \n",
       "3    I shut off the light in the unoccupied room.   effect      1  \n",
       "4                            The cook grilled it.    cause      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copa_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf4d961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The item was packaged in bubble wrap.</td>\n",
       "      <td>It was fragile.</td>\n",
       "      <td>It was small.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I emptied my pockets.</td>\n",
       "      <td>I retrieved a ticket stub.</td>\n",
       "      <td>I found a weapon.</td>\n",
       "      <td>effect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Termites invaded the house.</td>\n",
       "      <td>The termites disappeared from the house.</td>\n",
       "      <td>The termites ate through the wood in the house.</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The travelers reached the border.</td>\n",
       "      <td>The patrol agent checked their passports.</td>\n",
       "      <td>The patrol agent accused them of smuggling.</td>\n",
       "      <td>effect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The office was closed.</td>\n",
       "      <td>It was a holiday.</td>\n",
       "      <td>It was summer.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 premise  \\\n",
       "0  The item was packaged in bubble wrap.   \n",
       "1                  I emptied my pockets.   \n",
       "2            Termites invaded the house.   \n",
       "3      The travelers reached the border.   \n",
       "4                 The office was closed.   \n",
       "\n",
       "                                     choice1  \\\n",
       "0                            It was fragile.   \n",
       "1                 I retrieved a ticket stub.   \n",
       "2   The termites disappeared from the house.   \n",
       "3  The patrol agent checked their passports.   \n",
       "4                          It was a holiday.   \n",
       "\n",
       "                                           choice2 question  label  \n",
       "0                                    It was small.    cause      0  \n",
       "1                                I found a weapon.   effect      0  \n",
       "2  The termites ate through the wood in the house.   effect      1  \n",
       "3      The patrol agent accused them of smuggling.   effect      0  \n",
       "4                                   It was summer.    cause      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f57f005c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_sentence</th>\n",
       "      <th>candidates</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer0</th>\n",
       "      <th>answer1</th>\n",
       "      <th>answer2</th>\n",
       "      <th>text</th>\n",
       "      <th>covariates</th>\n",
       "      <th>interventions</th>\n",
       "      <th>index</th>\n",
       "      <th>outcome</th>\n",
       "      <th>answer_idx</th>\n",
       "      <th>covariates_cleaned</th>\n",
       "      <th>p_xd</th>\n",
       "      <th>p_dy</th>\n",
       "      <th>p_xy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They won regionals and were on the way to the ...</td>\n",
       "      <td>['The football team had worked hard all season...</td>\n",
       "      <td>The football team had worked hard all season. ...</td>\n",
       "      <td>The football team had worked hard all season.</td>\n",
       "      <td>They won regionals and were on their way to th...</td>\n",
       "      <td>During practice, the quarterback broke his arm.</td>\n",
       "      <td>The football team had worked hard all season.</td>\n",
       "      <td>[\"The football team had worked hard all season...</td>\n",
       "      <td>['The football team was new and worked hard al...</td>\n",
       "      <td>0</td>\n",
       "      <td>They won regionals and were on their way to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"He'd had to work even harder to overcome his...</td>\n",
       "      <td>[[(0.0734076276421547, 0.11186903121415526, 0....</td>\n",
       "      <td>[(0.46431438624858856, 0.4771946966648102), (0...</td>\n",
       "      <td>[(0.3315032720565796, 0.39027543365955353), (0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They won regionals and were on the way to the ...</td>\n",
       "      <td>['The football team had worked hard all season...</td>\n",
       "      <td>The football team had worked hard all season. ...</td>\n",
       "      <td>The football team had worked hard all season.</td>\n",
       "      <td>They won regionals and were on their way to th...</td>\n",
       "      <td>During practice, the quarterback broke his arm.</td>\n",
       "      <td>The football team had worked hard all season.</td>\n",
       "      <td>[\"The football team had worked hard all season...</td>\n",
       "      <td>['The football team was new and worked hard al...</td>\n",
       "      <td>0</td>\n",
       "      <td>During practice, the quarterback broke his arm.</td>\n",
       "      <td>2</td>\n",
       "      <td>[\"He'd had to work even harder to overcome his...</td>\n",
       "      <td>[[(0.0734076276421547, 0.11186903121415526, 0....</td>\n",
       "      <td>[(0.5384128838777542, 0.4292968362569809), (0....</td>\n",
       "      <td>[(0.2735405806452036, 0.187699181959033), (0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The team had to use the second string quarterb...</td>\n",
       "      <td>['The football team had worked hard all season...</td>\n",
       "      <td>The quarterback breaks his arm &gt;Causes/Enables...</td>\n",
       "      <td>The quarterback breaks his arm</td>\n",
       "      <td>The team has to use The second string quarterback</td>\n",
       "      <td>Luckily, the team still won the play-offs.</td>\n",
       "      <td>The quarterback breaks his arm</td>\n",
       "      <td>['The quarterback breaks his arm Before that, ...</td>\n",
       "      <td>['A player breaks his arm', 'A receiver breaks...</td>\n",
       "      <td>1</td>\n",
       "      <td>The team has to use The second string quarterback</td>\n",
       "      <td>1</td>\n",
       "      <td>['He had a cyst on his side,  he broke his wri...</td>\n",
       "      <td>[[(0.4629475921392441, 0.47641928493976593, 0....</td>\n",
       "      <td>[(0.4776032269001007, 0.5128596127033234), (0....</td>\n",
       "      <td>[(0.18337566778063774, 0.20733415335416794), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The team had to use the second string quarterb...</td>\n",
       "      <td>['The football team had worked hard all season...</td>\n",
       "      <td>The quarterback breaks his arm &gt;Causes/Enables...</td>\n",
       "      <td>The quarterback breaks his arm</td>\n",
       "      <td>The team has to use The second string quarterback</td>\n",
       "      <td>Luckily, the team still won the play-offs.</td>\n",
       "      <td>The quarterback breaks his arm</td>\n",
       "      <td>['The quarterback breaks his arm Before that, ...</td>\n",
       "      <td>['A player breaks his arm', 'A receiver breaks...</td>\n",
       "      <td>1</td>\n",
       "      <td>Luckily, the team still won the play-offs.</td>\n",
       "      <td>2</td>\n",
       "      <td>['He had a cyst on his side,  he broke his wri...</td>\n",
       "      <td>[[(0.4629475921392441, 0.47641928493976593, 0....</td>\n",
       "      <td>[(0.42544446885585785, 0.5650285333395004), (0...</td>\n",
       "      <td>[(0.3369382694363594, 0.3855547308921814), (0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I practiced all the time to be really good.</td>\n",
       "      <td>['When I was a kid I wanted to be really good ...</td>\n",
       "      <td>i want to be good at playing violin &gt;Causes/En...</td>\n",
       "      <td>i want to be good at playing violin</td>\n",
       "      <td>i practices a lot</td>\n",
       "      <td>After a few months of practicing I did get rea...</td>\n",
       "      <td>i want to be good at playing violin</td>\n",
       "      <td>['i want to be good at playing violin Before t...</td>\n",
       "      <td>[\"the door's a little higher than i want to be...</td>\n",
       "      <td>2</td>\n",
       "      <td>i practices a lot</td>\n",
       "      <td>1</td>\n",
       "      <td>['I was good at playing the flute,.', 'I want ...</td>\n",
       "      <td>[[(0.2706519067287445, 0.2139797806739807, 0.0...</td>\n",
       "      <td>[(0.45580950379371643, 0.5197682678699493), (0...</td>\n",
       "      <td>[(0.24025794863700867, 0.25716912746429443), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   selected_sentence  \\\n",
       "0  They won regionals and were on the way to the ...   \n",
       "1  They won regionals and were on the way to the ...   \n",
       "2  The team had to use the second string quarterb...   \n",
       "3  The team had to use the second string quarterb...   \n",
       "4        I practiced all the time to be really good.   \n",
       "\n",
       "                                          candidates  \\\n",
       "0  ['The football team had worked hard all season...   \n",
       "1  ['The football team had worked hard all season...   \n",
       "2  ['The football team had worked hard all season...   \n",
       "3  ['The football team had worked hard all season...   \n",
       "4  ['When I was a kid I wanted to be really good ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The football team had worked hard all season. ...   \n",
       "1  The football team had worked hard all season. ...   \n",
       "2  The quarterback breaks his arm >Causes/Enables...   \n",
       "3  The quarterback breaks his arm >Causes/Enables...   \n",
       "4  i want to be good at playing violin >Causes/En...   \n",
       "\n",
       "                                         answer0  \\\n",
       "0  The football team had worked hard all season.   \n",
       "1  The football team had worked hard all season.   \n",
       "2                 The quarterback breaks his arm   \n",
       "3                 The quarterback breaks his arm   \n",
       "4            i want to be good at playing violin   \n",
       "\n",
       "                                             answer1  \\\n",
       "0  They won regionals and were on their way to th...   \n",
       "1  They won regionals and were on their way to th...   \n",
       "2  The team has to use The second string quarterback   \n",
       "3  The team has to use The second string quarterback   \n",
       "4                                  i practices a lot   \n",
       "\n",
       "                                             answer2  \\\n",
       "0    During practice, the quarterback broke his arm.   \n",
       "1    During practice, the quarterback broke his arm.   \n",
       "2         Luckily, the team still won the play-offs.   \n",
       "3         Luckily, the team still won the play-offs.   \n",
       "4  After a few months of practicing I did get rea...   \n",
       "\n",
       "                                            text  \\\n",
       "0  The football team had worked hard all season.   \n",
       "1  The football team had worked hard all season.   \n",
       "2                 The quarterback breaks his arm   \n",
       "3                 The quarterback breaks his arm   \n",
       "4            i want to be good at playing violin   \n",
       "\n",
       "                                          covariates  \\\n",
       "0  [\"The football team had worked hard all season...   \n",
       "1  [\"The football team had worked hard all season...   \n",
       "2  ['The quarterback breaks his arm Before that, ...   \n",
       "3  ['The quarterback breaks his arm Before that, ...   \n",
       "4  ['i want to be good at playing violin Before t...   \n",
       "\n",
       "                                       interventions  index  \\\n",
       "0  ['The football team was new and worked hard al...      0   \n",
       "1  ['The football team was new and worked hard al...      0   \n",
       "2  ['A player breaks his arm', 'A receiver breaks...      1   \n",
       "3  ['A player breaks his arm', 'A receiver breaks...      1   \n",
       "4  [\"the door's a little higher than i want to be...      2   \n",
       "\n",
       "                                             outcome  answer_idx  \\\n",
       "0  They won regionals and were on their way to th...           1   \n",
       "1    During practice, the quarterback broke his arm.           2   \n",
       "2  The team has to use The second string quarterback           1   \n",
       "3         Luckily, the team still won the play-offs.           2   \n",
       "4                                  i practices a lot           1   \n",
       "\n",
       "                                  covariates_cleaned  \\\n",
       "0  [\"He'd had to work even harder to overcome his...   \n",
       "1  [\"He'd had to work even harder to overcome his...   \n",
       "2  ['He had a cyst on his side,  he broke his wri...   \n",
       "3  ['He had a cyst on his side,  he broke his wri...   \n",
       "4  ['I was good at playing the flute,.', 'I want ...   \n",
       "\n",
       "                                                p_xd  \\\n",
       "0  [[(0.0734076276421547, 0.11186903121415526, 0....   \n",
       "1  [[(0.0734076276421547, 0.11186903121415526, 0....   \n",
       "2  [[(0.4629475921392441, 0.47641928493976593, 0....   \n",
       "3  [[(0.4629475921392441, 0.47641928493976593, 0....   \n",
       "4  [[(0.2706519067287445, 0.2139797806739807, 0.0...   \n",
       "\n",
       "                                                p_dy  \\\n",
       "0  [(0.46431438624858856, 0.4771946966648102), (0...   \n",
       "1  [(0.5384128838777542, 0.4292968362569809), (0....   \n",
       "2  [(0.4776032269001007, 0.5128596127033234), (0....   \n",
       "3  [(0.42544446885585785, 0.5650285333395004), (0...   \n",
       "4  [(0.45580950379371643, 0.5197682678699493), (0...   \n",
       "\n",
       "                                                p_xy  \n",
       "0  [(0.3315032720565796, 0.39027543365955353), (0...  \n",
       "1  [(0.2735405806452036, 0.187699181959033), (0.2...  \n",
       "2  [(0.18337566778063774, 0.20733415335416794), (...  \n",
       "3  [(0.3369382694363594, 0.3855547308921814), (0....  \n",
       "4  [(0.24025794863700867, 0.25716912746429443), (...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glt_d1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-monaco",
   "metadata": {},
   "source": [
    "# ROCK Pipeline\n",
    "\n",
    "[spacy en_core_web_md](https://spacy.io/models/en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4e4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md \n",
    "## First download the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inappropriate-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load('en_core_web_md')\n",
    "allensrl = src.pipeline.AllenSRLWrapper(allennlp_models.pretrained.load_predictor(\"structured-prediction-srl-bert\", cuda_device=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-martial",
   "metadata": {},
   "source": [
    "## Temporal Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-mailing",
   "metadata": {},
   "source": [
    "As a bare minimum, a customized temporal predictor needs to overwrite the `predict` method.\n",
    "Below is the implmentation we used based on mask language modeling.\n",
    "\n",
    "```python\n",
    "class TempPredictor:\n",
    "    def __init__(self, model, tokenizer, device, spacy_model=\"en_core_web_sm\"):\n",
    "        self._model = model\n",
    "        self._model.to(device)\n",
    "        self._model.eval()\n",
    "        self._tokenizer = tokenizer\n",
    "        self._mtoken = self._tokenizer.mask_token\n",
    "        self.unmasker = transformers.pipeline(\"fill-mask\", model=self._model, tokenizer=self._tokenizer, device=0)\n",
    "        try:\n",
    "            self._spacy = spacy.load(spacy_model)\n",
    "        except Exception as e:\n",
    "            self._spacy = spacy.load(\"en_core_web_sm\")\n",
    "            print(f\"Failed to load spacy model {spacy_model}, use default 'en_core_web_sm'\\n{e}\")\n",
    "\n",
    "\n",
    "    def predict(self, e1, e2, top_k=5):\n",
    "        \"\"\"\n",
    "        returns\n",
    "        \"\"\"\n",
    "        txt = self._remove_punct(e1) + \" \" + self._mtoken + \" \" + self._sent_lowercase(e2)\n",
    "        return self.unmasker(txt, top_k=top_k)\n",
    "\n",
    "\n",
    "    def get_temp(self, e1, e2, top_k=5, crop=1):\n",
    "        inst1 = self.predict(e1, e2, top_k)\n",
    "        inst2 = self.predict(e2, e1, top_k)\n",
    "\n",
    "        # e1 before e2\n",
    "        b1 = self._extract_token_prob(inst1, \"before\", crop=crop)\n",
    "        b2 = self._extract_token_prob(inst2, \"after\", crop=crop)\n",
    "\n",
    "        # e1 after e2\n",
    "        a1 = self._extract_token_prob(inst1, \"after\", crop=crop)\n",
    "        a2 = self._extract_token_prob(inst2, \"before\", crop=crop)\n",
    "\n",
    "        return (b1+b2)/2, (a1+a2)/2\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.get_temp(*args, **kwargs)\n",
    "    \n",
    "    # other methods omitted\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-probability",
   "metadata": {},
   "source": [
    "**NB** Fine-tuned RoBERTa model checkpoint can be downloaded using [this anonymous Dropbox link](https://www.dropbox.com/s/9egrzn1ny3oq2qa/roberta_ft.tar.gz?dl=0) (1.29GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unable-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_roberta_ft = src.pipeline.TempPredictor(\n",
    "    model=RobertaForMaskedLM.from_pretrained(MODEL_PATH/\"roberta_ft\"),\n",
    "    tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\"),\n",
    "    device=TORCH_DEV\n",
    ")\n",
    "\n",
    "tp_roberta_base = src.pipeline.TempPredictor(\n",
    "    model=RobertaForMaskedLM.from_pretrained(\"roberta-base\"),\n",
    "    tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\"),\n",
    "    device=TORCH_DEV\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-extent",
   "metadata": {},
   "source": [
    "##### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "encouraging-husband",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: The man turned on the faucet.\n",
      "C1: The toilet filled with water.\n",
      "C2: Water flowed from the spout.\n",
      "Question: effect\tCorrect choice: Choice 2\n",
      "\n",
      "============== PREMISE <---> CHOICE 1\n",
      "The man turned on the faucet. <---> The toilet filled with water.\n",
      "Base model:\tbefore: 0.081\tafter: 0.017\n",
      "FT model:\tbefore: 0.456\tafter: 0.498\n",
      "\n",
      "============== PREMISE <---> CHOICE 2 (expect before > after)\n",
      "The man turned on the faucet. <---> Water flowed from the spout.\n",
      "Base model:\tbefore: 0.107\tafter: 0.007\n",
      "FT model:\tbefore: 0.525\tafter: 0.472\n"
     ]
    }
   ],
   "source": [
    "utils.test_copa_run(copa_dev.iloc[0], tp_roberta_base, tp_roberta_ft, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eced96ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for idx in range(len(copa_dev)):\n",
    "    premise, choice1, choice2, q, lb = copa_dev.iloc[idx][['premise', 'choice1', 'choice2', 'question', 'label']]\n",
    "    predictor = tp_roberta_base\n",
    "    res = [predictor.get_temp(premise, choice1, top_k=5), predictor.get_temp(premise, choice2, top_k=5)]\n",
    "    r = res[lb]\n",
    "    if (q == \"effect\" and r[0] > r[1]) or (q == \"cause\" and r[0] < r[1]):\n",
    "        count += 1\n",
    "\n",
    "count / len(copa_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dabdc5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for idx in range(len(copa_dev)):\n",
    "    premise, choice1, choice2, q, lb = copa_dev.iloc[idx][['premise', 'choice1', 'choice2', 'question', 'label']]\n",
    "    predictor = tp_roberta_ft\n",
    "    res = [predictor.get_temp(premise, choice1, top_k=5), predictor.get_temp(premise, choice2, top_k=5)]\n",
    "    r = res[lb]\n",
    "    if (q == \"effect\" and r[0] > r[1]) or (q == \"cause\" and r[0] < r[1]):\n",
    "        count += 1\n",
    "\n",
    "count / len(copa_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-subscriber",
   "metadata": {},
   "source": [
    "## Event Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-robinson",
   "metadata": {},
   "source": [
    "The event sampler subclasses `EventGenerator`.\n",
    "As a bare minimum, a custom implmentation should provide the `__call__` method.\n",
    "\n",
    "```python\n",
    "class EventGenerator:\n",
    "    def __init__(self, model, tokenizer, spacy_model, device):\n",
    "        self.model = model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, prompt, max_length=30, **kwargs):\n",
    "        # pass\n",
    "```\n",
    "\n",
    "Below is our wrapper for GPT-J that is used in our paper:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "class GPTJGenerator:\n",
    "    def __init__(self, model, tokenizer, device=None):\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "        if device is not None:\n",
    "            self.model = self.model.to(device)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, prompt, **kwargs):\n",
    "        output_id = self.model.generate(self.tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids, **kwargs)\n",
    "        return self.tokenizer.batch_decode(output_id)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "macro-meditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03ac94c95714412a70ce7785029a9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/22.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      2\u001b[0m gptj_tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mEleutherAI/gpt-j-6B\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m gptj_model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mEleutherAI/gpt-j-6B\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    445\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    447\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/modeling_utils.py:2007\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     archive_file \u001b[39m=\u001b[39m hf_bucket_url(\n\u001b[1;32m   2002\u001b[0m         pretrained_model_name_or_path, filename\u001b[39m=\u001b[39mfilename, revision\u001b[39m=\u001b[39mrevision, mirror\u001b[39m=\u001b[39mmirror\n\u001b[1;32m   2003\u001b[0m     )\n\u001b[1;32m   2005\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 2007\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m   2008\u001b[0m         archive_file,\n\u001b[1;32m   2009\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2010\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2011\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2012\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2013\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2014\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   2015\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   2016\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m   2019\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2020\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtoken having permission to this repo with `use_auth_token` or log in with `huggingface-cli \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlogin` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    285\u001b[0m         url_or_filename,\n\u001b[1;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:594\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[1;32m    592\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[39m{\u001b[39;00mtemp_file\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     http_get(url_to_download, temp_file, proxies\u001b[39m=\u001b[39;49mproxies, resume_size\u001b[39m=\u001b[39;49mresume_size, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    596\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    597\u001b[0m os\u001b[39m.\u001b[39mreplace(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:446\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m# `tqdm` behavior is determined by `utils.logging.is_progress_bar_enabled()`\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m# and can be set using `utils.logging.enable/disable_progress_bar()`\u001b[39;00m\n\u001b[1;32m    438\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[1;32m    439\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m )\n\u001b[0;32m--> 446\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:524\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     chunk_amt \u001b[39m=\u001b[39m max_chunk_amt\n\u001b[0;32m--> 524\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(chunk_amt)\n\u001b[1;32m    525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    526\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "gptj_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "gptj_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_generator = src.pipeline.GPTJGenerator(model=gptj_model, tokenizer=gptj_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = dict(max_length=30,\n",
    "                  do_sample=True,\n",
    "                  temperature=0.9,\n",
    "                  num_return_sequences=10,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sents = gpt_generator(\"The man turned on the faucet.\", **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-johns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man turned on the faucet. His face was a mask of concentration, and his hands were steady as he washed the car.\n",
      "\n",
      "\n",
      "The man turned on the faucet. It was a small plastic one, nothing fancy. His hands shook, but he managed to turn the water\n",
      "The man turned on the faucet. He drank from it until the bottle was empty.\n",
      "\n",
      "After a moment he pulled the cap off the\n",
      "The man turned on the faucet. Water began splashing into the sink. He was washing the dishes, his expression blank, his eyes dead\n",
      "The man turned on the faucet.\n",
      "\n",
      "Bruno had to take a step back. The water made a sound. The man looked\n",
      "The man turned on the faucet. The water gushed out. A loud splash, and water went everywhere, flowing down the man's body\n",
      "The man turned on the faucet. He watched it fill with cold water. He heard it gurgle into the sink. He watched it\n",
      "The man turned on the faucet. He scrubbed down the sink and the tub, washed the toilet bowl, then flushed. In the meantime\n",
      "The man turned on the faucet. A strong current of water hit him in the face. He wiped it away and spat. The sink was\n",
      "The man turned on the faucet. He took off his tie and loosened his collar. No, not his collar; his shirt. He\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(gen_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-london",
   "metadata": {},
   "source": [
    "## Interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-samuel",
   "metadata": {},
   "source": [
    "As a bare minimum, the intervention generator should\n",
    "implement `__call__` method that takes a prompt and additional\n",
    "kwargs as arguments and return a list of interventions.\n",
    "\n",
    "```python\n",
    "class InterventionGenerator:\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, prompt, **kwargs:)\n",
    "        pass\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "We use PolyJuice in our implementation based on their implementation [0].\n",
    "\n",
    "\n",
    "[0] https://github.com/tongshuangwu/polyjuice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "martial-legend",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b507d2e29c2744df94e05f474face0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab8ca70216b4ffe91bacbc5a2645ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/487M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cf_gen \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mPJGenerator(srl_processor\u001b[39m=\u001b[39;49mallensrl)\n",
      "File \u001b[0;32m~/Windlike_repo/ccr_rock/src/pipeline.py:181\u001b[0m, in \u001b[0;36mPJGenerator.__init__\u001b[0;34m(self, model_path, spacy_processor, device, srl_processor)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muw-hai/polyjuice\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    175\u001b[0m              spacy_processor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m              device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    177\u001b[0m              srl_processor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m             ):\n\u001b[1;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m    180\u001b[0m     generator \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 181\u001b[0m         model\u001b[39m=\u001b[39mAutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_path),\n\u001b[1;32m    182\u001b[0m         tokenizer\u001b[39m=\u001b[39mAutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_path),\n\u001b[1;32m    183\u001b[0m         framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    184\u001b[0m     generator\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39meos_token\n\u001b[1;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator \u001b[39m=\u001b[39m generator\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    445\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    447\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/modeling_utils.py:2007\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     archive_file \u001b[39m=\u001b[39m hf_bucket_url(\n\u001b[1;32m   2002\u001b[0m         pretrained_model_name_or_path, filename\u001b[39m=\u001b[39mfilename, revision\u001b[39m=\u001b[39mrevision, mirror\u001b[39m=\u001b[39mmirror\n\u001b[1;32m   2003\u001b[0m     )\n\u001b[1;32m   2005\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 2007\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m   2008\u001b[0m         archive_file,\n\u001b[1;32m   2009\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2010\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2011\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2012\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2013\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2014\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   2015\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   2016\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m   2019\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2020\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtoken having permission to this repo with `use_auth_token` or log in with `huggingface-cli \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlogin` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    285\u001b[0m         url_or_filename,\n\u001b[1;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:594\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[1;32m    592\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[39m{\u001b[39;00mtemp_file\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     http_get(url_to_download, temp_file, proxies\u001b[39m=\u001b[39;49mproxies, resume_size\u001b[39m=\u001b[39;49mresume_size, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    596\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    597\u001b[0m os\u001b[39m.\u001b[39mreplace(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/transformers/utils/hub.py:446\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m# `tqdm` behavior is determined by `utils.logging.is_progress_bar_enabled()`\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m# and can be set using `utils.logging.enable/disable_progress_bar()`\u001b[39;00m\n\u001b[1;32m    438\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[1;32m    439\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m )\n\u001b[0;32m--> 446\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/site-packages/urllib3/response.py:532\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cf_gen = src.pipeline.PJGenerator(srl_processor=allensrl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_texts = cf_gen(\"The man turned off the faucet.\",\n",
    "      ctrl_codes=[\n",
    "          \"resemantic\", \n",
    "          \"negation\", \n",
    "          \"lexical\",\n",
    "          \"quantifier\"\n",
    "          \"insert\",\n",
    "          \"restructure\",\n",
    "          \"shuffle\",\n",
    "          \"delete\"\n",
    "                 ]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The woman turned off the faucet.\n",
      "The man turned off the faucet.\n",
      "The man poured water from the watering can into the pitcher until the watering can was empty. off the faucet.\n",
      "The man replaced the bell brand off the faucet.\n",
      "The man lit the cigarette off the faucet.\n",
      "The man turned off the water main.\n",
      "The man turned off the dishwasher.\n",
      "The man turned off the fan and replaced it with a fan outside of his house.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(cf_texts['resemantic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-subscriber",
   "metadata": {},
   "source": [
    "## Processing Datasets for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-incident",
   "metadata": {},
   "source": [
    "### Construct DataFrames for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_copa_proc_df(copa):\n",
    "    return pd.DataFrame(list(itertools.chain.from_iterable(\n",
    "        [[s[0], 'premise', s[1]['premise']]] if s[1]['question'] == 'effect'\n",
    "        else [[s[0], 'choice1', s[1]['choice1']], [s[0], 'choice2', s[1]['choice2']]]\n",
    "        for s in copa.iterrows()\n",
    "    )), columns=['index', 'name', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_proc = gen_copa_proc_df(copa_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>premise</td>\n",
       "      <td>The man turned on the faucet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>premise</td>\n",
       "      <td>The girl found a bug in her cereal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>premise</td>\n",
       "      <td>The woman retired.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>premise</td>\n",
       "      <td>I wanted to conserve energy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>choice1</td>\n",
       "      <td>The cook froze it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     name                                 text\n",
       "0      0  premise        The man turned on the faucet.\n",
       "1      1  premise  The girl found a bug in her cereal.\n",
       "2      2  premise                   The woman retired.\n",
       "3      3  premise         I wanted to conserve energy.\n",
       "4      4  choice1                   The cook froze it."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copa_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-dietary",
   "metadata": {},
   "source": [
    "We can apply the components row by row, but it is more efficient to let\n",
    "each component batch process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-surface",
   "metadata": {},
   "source": [
    "#### Sample Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cov(df, model, tokenizer):\n",
    "    output_ids = []\n",
    "    for s in df.iterrows():\n",
    "        prompt = f\"{s[1]['text']} Before that, \"\n",
    "\n",
    "        gen_tokens = model.generate(tokenizer(prompt,\n",
    "                          return_tensors=\"pt\", padding=True).input_ids, \n",
    "                    do_sample=True,\n",
    "                    temperature=0.9,\n",
    "                    max_length=30,\n",
    "                    num_return_sequences=100,\n",
    "            )\n",
    "        output_ids.append(gen_tokens)\n",
    "    return [tokenizer.batch_decode(tks) for tks in output_ids]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_proc['covariates'] = sample_cov(copa_proc, gptj_model, gptj_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-semiconductor",
   "metadata": {},
   "source": [
    "#### Generating Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interventions(self, s, cf_gen, **kwargs):\n",
    "    interventions = self.cf_gen(s, gen_kwargs=kwargs)\n",
    "    intvers = list(itertools.chain(*[ints for _, ints in interventions.items()]))\n",
    "    self.last_gen['interventions'] = intvers\n",
    "    return intvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_proc['interventions'] = copa_proc.apply(lambda s : get_interventions(s, cf_gen, \n",
    "                                ctrl_codes=[\n",
    "                                      \"resemantic\", \n",
    "                                      \"negation\", \n",
    "                                      \"lexical\",\n",
    "                                      \"quantifier\"\n",
    "                                      \"insert\",\n",
    "                                      \"restructure\",\n",
    "                                      \"shuffle\",\n",
    "                                      \"delete\"\n",
    "                                ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-bread",
   "metadata": {},
   "source": [
    "### Obtain Temporal Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `utils.glt_get_probs`\n",
    "# if working on glucose-d1\n",
    "copa_proc = copa_proc.apply(lambda s : utils.copa_get_probs(s, model=tp_roberta_ft, \n",
    "                                                            top_k=5, spacy_model=spacy_model), \n",
    "                            axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-setting",
   "metadata": {},
   "source": [
    "#### Add a few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postproc_copa(df):\n",
    "    df['label_idx'] = df['name'].apply(\n",
    "        lambda s: -1 if s == 'premise' else int(s[-1])-1\n",
    "    )\n",
    "\n",
    "    df['outcome'] = df.apply(lambda s:\n",
    "        None if s['label_idx'] == -1 else copa_test.iloc[s['index']]['premise'], axis=1)\n",
    "\n",
    "\n",
    "    tmp_df = df[df['label_idx']==-1].copy()\n",
    "    tmp_df['label_idx'] = 1\n",
    "    df.loc[df['label_idx']==-1, 'label_idx']=0\n",
    "    df = pd.concat([df, tmp_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_proc = postproc_copa(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-spank",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-flooring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>covariates</th>\n",
       "      <th>interventions</th>\n",
       "      <th>outcome</th>\n",
       "      <th>label_idx</th>\n",
       "      <th>p_xd</th>\n",
       "      <th>p_dy</th>\n",
       "      <th>p_xy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>premise</td>\n",
       "      <td>The man turned on the faucet.</td>\n",
       "      <td>[\"The man turned on the faucet. Before that, h...</td>\n",
       "      <td>['The man chose to turned on the faucet.', 'At...</td>\n",
       "      <td>The toilet filled with water.</td>\n",
       "      <td>0</td>\n",
       "      <td>[[(0.210379958152771, 0.30398909747600555, 0.0...</td>\n",
       "      <td>[(0.45566828548908234, 0.4977114349603653), (0...</td>\n",
       "      <td>[(0.04539947956800461, 0.03326283395290375), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>premise</td>\n",
       "      <td>The man turned on the faucet.</td>\n",
       "      <td>[\"The man turned on the faucet. Before that, h...</td>\n",
       "      <td>['The man chose to turned on the faucet.', 'At...</td>\n",
       "      <td>Water flowed from the spout.</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(0.210379958152771, 0.30398909747600555, 0.0...</td>\n",
       "      <td>[(0.5247508734464645, 0.4717450588941574), (0....</td>\n",
       "      <td>[(0.3355148509144783, 0.25840914994478226), (0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>premise</td>\n",
       "      <td>The girl found a bug in her cereal.</td>\n",
       "      <td>[\"The girl found a bug in her cereal. Before t...</td>\n",
       "      <td>['While digging for well water Monica stayed o...</td>\n",
       "      <td>She poured milk in the bowl.</td>\n",
       "      <td>0</td>\n",
       "      <td>[[(0.5899830460548401, 0.39629100263118744, 0....</td>\n",
       "      <td>[(0.47232694923877716, 0.5270598828792572), (0...</td>\n",
       "      <td>[(0.5464454889297485, 0.40834908187389374), (0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>premise</td>\n",
       "      <td>The girl found a bug in her cereal.</td>\n",
       "      <td>[\"The girl found a bug in her cereal. Before t...</td>\n",
       "      <td>['While digging for well water Monica stayed o...</td>\n",
       "      <td>She lost her appetite.</td>\n",
       "      <td>1</td>\n",
       "      <td>[[(0.5899830460548401, 0.39629100263118744, 0....</td>\n",
       "      <td>[(0.4848470687866211, 0.5141351819038391), (0....</td>\n",
       "      <td>[(0.6019861996173859, 0.38734038174152374), (0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>premise</td>\n",
       "      <td>The woman retired.</td>\n",
       "      <td>[\"The woman retired. Before that, she'd writte...</td>\n",
       "      <td>['Suddenly the woman retired.', 'The author ra...</td>\n",
       "      <td>She received her pension.</td>\n",
       "      <td>0</td>\n",
       "      <td>[[(0.3462740257382393, 0.30608220398426056, 0....</td>\n",
       "      <td>[(0.4986240118741989, 0.49911610782146454), (0...</td>\n",
       "      <td>[(0.5325719714164734, 0.45344893634319305), (0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     name                                 text  \\\n",
       "0      0  premise        The man turned on the faucet.   \n",
       "1      0  premise        The man turned on the faucet.   \n",
       "2      1  premise  The girl found a bug in her cereal.   \n",
       "3      1  premise  The girl found a bug in her cereal.   \n",
       "4      2  premise                   The woman retired.   \n",
       "\n",
       "                                          covariates  \\\n",
       "0  [\"The man turned on the faucet. Before that, h...   \n",
       "1  [\"The man turned on the faucet. Before that, h...   \n",
       "2  [\"The girl found a bug in her cereal. Before t...   \n",
       "3  [\"The girl found a bug in her cereal. Before t...   \n",
       "4  [\"The woman retired. Before that, she'd writte...   \n",
       "\n",
       "                                       interventions  \\\n",
       "0  ['The man chose to turned on the faucet.', 'At...   \n",
       "1  ['The man chose to turned on the faucet.', 'At...   \n",
       "2  ['While digging for well water Monica stayed o...   \n",
       "3  ['While digging for well water Monica stayed o...   \n",
       "4  ['Suddenly the woman retired.', 'The author ra...   \n",
       "\n",
       "                         outcome  label_idx  \\\n",
       "0  The toilet filled with water.          0   \n",
       "1   Water flowed from the spout.          1   \n",
       "2   She poured milk in the bowl.          0   \n",
       "3         She lost her appetite.          1   \n",
       "4      She received her pension.          0   \n",
       "\n",
       "                                                p_xd  \\\n",
       "0  [[(0.210379958152771, 0.30398909747600555, 0.0...   \n",
       "1  [[(0.210379958152771, 0.30398909747600555, 0.0...   \n",
       "2  [[(0.5899830460548401, 0.39629100263118744, 0....   \n",
       "3  [[(0.5899830460548401, 0.39629100263118744, 0....   \n",
       "4  [[(0.3462740257382393, 0.30608220398426056, 0....   \n",
       "\n",
       "                                                p_dy  \\\n",
       "0  [(0.45566828548908234, 0.4977114349603653), (0...   \n",
       "1  [(0.5247508734464645, 0.4717450588941574), (0....   \n",
       "2  [(0.47232694923877716, 0.5270598828792572), (0...   \n",
       "3  [(0.4848470687866211, 0.5141351819038391), (0....   \n",
       "4  [(0.4986240118741989, 0.49911610782146454), (0...   \n",
       "\n",
       "                                                p_xy  \n",
       "0  [(0.04539947956800461, 0.03326283395290375), (...  \n",
       "1  [(0.3355148509144783, 0.25840914994478226), (0...  \n",
       "2  [(0.5464454889297485, 0.40834908187389374), (0...  \n",
       "3  [(0.6019861996173859, 0.38734038174152374), (0...  \n",
       "4  [(0.5325719714164734, 0.45344893634319305), (0...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copa_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_proc.to_csv(DATA_PATH/\"copa_dev_probs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-strap",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Please see `result_presentation.ipynb` notebook for evaulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ccr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4519cf99bfb3ec48c7804c863c6017733afbf5f6023ed3cc7b3a74753d82ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
